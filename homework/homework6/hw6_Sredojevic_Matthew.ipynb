{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Hypothesis Testing, P-Hacking, and Simple Linear Regression \n",
    "***\n",
    "\n",
    "**Name**: Matthew Sredojevic\n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5pm on Friday April 20th**. Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**.  For a refresher on the course **Collaboration Policy** click [here](https://github.com/dblarremore/csci3022/blob/master/resources/syllabus.md#collaboration-policy).\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do Cell $\\rightarrow$ Run All as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "from scipy import stats \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [15 points] Problem 1 - Hypothesis Testing: Find-the-Knowledge-Bug \n",
    "***\n",
    "\n",
    "As part of your job as a seasoned data science consultant, companies often bring you in to supervise their less-experienced data science teams before new product roll-outs.  On one such occasion, you are hired by a medium-sized internet-sales company that is preparing to release a new line of smart-home products.  Prior to their product release the company wants to do a targeted ad campaign to drive traffic to their site on launch day. \n",
    "\n",
    "You are asked to pair-up and do some inference work with a new employee named Stevey McKnowsNoStats. At various points in your day you catch Stevey making the following mistakes.  In each case, clearly explain to Stevey why his testing setup or conclusion is incorrect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Stevey has pulled up some data on the characteristics of customers that visited the company's website over the previous month.  He wants to perform an analysis on the mean age of customers that visit the site.  Let $X$ be the random variable describing the age of a site visitor and suppose that the population mean for $X$ is $\\mu$. In particular, Stevey wants to see if the data suggests that the mean age of their customers is under 30 years old.   He decides to perform the test with a null hypothesis of $H_0: \\bar{x} = 30$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "Stevey, you idiot, you're using the wrong average. Youre using the population mean, where instead you should be using the dataset mean. instead of $\\bar{x}$, you should be using $\\mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: After the wonderful explanation you gave him after the previous debacle, Stevey has seen the error in his ways and decides instead to do his hypothesis test with a null hypothesis of $H_0: \\mu < 30$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "No, Stevey. The null hypothesis needs to be what we assume from the data initailly. it shouldn't be  $\\mu < 30$, but intead we'll assume that the average IS 30. Your Null hypothesis should read as $H_0: \\mu = 30$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Finally on track with reasonable hypotheses of $H_0: \\mu = 30$ and $H_1: \\mu < 30$, Stevey computes a normalized test-statistic of $z = -1.35$ for the mean age and concludes that since $z = -1.35 < 0.05$ there is sufficient statistical evidence at the $\\alpha = 0.05$ significance level that the mean age of their customers is less than 30.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Oh, Stevey, you do not give me hope for humanity. $\\alpha$ isn't the value you compare to your z value. You first need to find the z-value for $\\alpha = 0.05$($z_{\\alpha}$) and then compare those values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: This time, with the hypotheses again $H_0: \\mu = 30$ and $H_1: \\mu < 30$, Stevey computes a p-value of $0.03$, and thus concludes that there is only a 3% probability that the null hypothesis is true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Well, the p-value you calculated, Im ASSUMING youre comparing it to the previous $\\alpha = 0.05$ and since the p-value is smaler than $\\alpha$ so you can REJECT the Null Hypothesis. We know at LEAST that the null hypothesis is not true because we were able to reject it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 points] Problem 2 - Scientists vs. P-Values \n",
    "***\n",
    "\n",
    "Read the following article from **FiveThirtyEight**: [Statisticians Found One Thing They Can Agree On: It's Time to Stop Misusing P-Values](http://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/). In what ways are scientists misusing p-values?  What suggestions are being made to use them properly? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is being used to confirm hypothesis' that people are trying to prove, where instead the p-value is actually showing an accuracy of the data to the null hypothesis\n",
    "\n",
    "Some of the suggestions are to rely less of p-values overall and instead use other tests 'such as confidence intervals or Bayesian analyses.', where as others believe that will lead to the same issue with these different tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [20 points] Problem 3 - Evaluating Pizza Delivery Performance \n",
    "***\n",
    "\n",
    "The manager of a pizza chain with multiple locations likes to keep meticulous data on his pizza deliveries.  The data from more than 1200 deliveries in May 2014 is stored in pizza.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1235)\n",
    "dfP = pd.read_csv(\"data/pizza.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>operator</th>\n",
       "      <th>branch</th>\n",
       "      <th>driver</th>\n",
       "      <th>temperature</th>\n",
       "      <th>bill</th>\n",
       "      <th>pizzas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>33.708636</td>\n",
       "      <td>Laura</td>\n",
       "      <td>East</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>71.433084</td>\n",
       "      <td>58.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>29.382070</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>East</td>\n",
       "      <td>Salvatore</td>\n",
       "      <td>64.952920</td>\n",
       "      <td>26.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>33.580664</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>West</td>\n",
       "      <td>Salvatore</td>\n",
       "      <td>49.113452</td>\n",
       "      <td>58.1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>32.505369</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>East</td>\n",
       "      <td>Salvatore</td>\n",
       "      <td>64.872559</td>\n",
       "      <td>35.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>25.493613</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>West</td>\n",
       "      <td>Salvatore</td>\n",
       "      <td>59.630052</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>21.727466</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>53.715391</td>\n",
       "      <td>61.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>38.394169</td>\n",
       "      <td>Laura</td>\n",
       "      <td>West</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>60.266862</td>\n",
       "      <td>57.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>22.186179</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>West</td>\n",
       "      <td>Mario</td>\n",
       "      <td>61.187654</td>\n",
       "      <td>35.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>35.324994</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Mario</td>\n",
       "      <td>64.204093</td>\n",
       "      <td>36.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>34.015280</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>67.383452</td>\n",
       "      <td>44.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>33.792085</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>70.983051</td>\n",
       "      <td>49.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>29.131207</td>\n",
       "      <td>Laura</td>\n",
       "      <td>East</td>\n",
       "      <td>Mario</td>\n",
       "      <td>69.949241</td>\n",
       "      <td>49.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>21.926461</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>West</td>\n",
       "      <td>Mario</td>\n",
       "      <td>60.798941</td>\n",
       "      <td>41.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>28.185400</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Salvatore</td>\n",
       "      <td>72.440348</td>\n",
       "      <td>42.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>32.603202</td>\n",
       "      <td>Laura</td>\n",
       "      <td>West</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>63.111336</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>32.648734</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>West</td>\n",
       "      <td>Salvatore</td>\n",
       "      <td>55.732293</td>\n",
       "      <td>41.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>37.398504</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Mario</td>\n",
       "      <td>54.507040</td>\n",
       "      <td>34.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>33.956136</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>East</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>58.103934</td>\n",
       "      <td>42.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>26.379708</td>\n",
       "      <td>Laura</td>\n",
       "      <td>East</td>\n",
       "      <td>Mario</td>\n",
       "      <td>56.517764</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01-May-14</td>\n",
       "      <td>33.193288</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>Centre</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>48.759259</td>\n",
       "      <td>47.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         day       date       time operator  branch     driver  temperature  \\\n",
       "0   Thursday  01-May-14  33.708636    Laura    East      Bruno    71.433084   \n",
       "1   Thursday  01-May-14  29.382070  Melissa    East  Salvatore    64.952920   \n",
       "2   Thursday  01-May-14  33.580664  Melissa    West  Salvatore    49.113452   \n",
       "3   Thursday  01-May-14  32.505369  Melissa    East  Salvatore    64.872559   \n",
       "4   Thursday  01-May-14  25.493613  Melissa    West  Salvatore    59.630052   \n",
       "5   Thursday  01-May-14  21.727466  Melissa  Centre      Bruno    53.715391   \n",
       "6   Thursday  01-May-14  38.394169    Laura    West      Bruno    60.266862   \n",
       "7   Thursday  01-May-14  22.186179  Melissa    West      Mario    61.187654   \n",
       "8   Thursday  01-May-14  35.324994    Laura  Centre      Mario    64.204093   \n",
       "9   Thursday  01-May-14  34.015280  Melissa  Centre      Bruno    67.383452   \n",
       "10  Thursday  01-May-14  33.792085  Melissa  Centre      Bruno    70.983051   \n",
       "11  Thursday  01-May-14  29.131207    Laura    East      Mario    69.949241   \n",
       "12  Thursday  01-May-14  21.926461  Melissa    West      Mario    60.798941   \n",
       "13  Thursday  01-May-14  28.185400  Melissa  Centre  Salvatore    72.440348   \n",
       "14  Thursday  01-May-14  32.603202    Laura    West      Bruno    63.111336   \n",
       "15  Thursday  01-May-14  32.648734  Melissa    West  Salvatore    55.732293   \n",
       "16  Thursday  01-May-14  37.398504  Melissa  Centre      Mario    54.507040   \n",
       "17  Thursday  01-May-14  33.956136  Melissa    East      Bruno    58.103934   \n",
       "18  Thursday  01-May-14  26.379708    Laura    East      Mario    56.517764   \n",
       "19  Thursday  01-May-14  33.193288  Melissa  Centre      Bruno    48.759259   \n",
       "\n",
       "    bill  pizzas  \n",
       "0   58.4       4  \n",
       "1   26.4       2  \n",
       "2   58.1       3  \n",
       "3   35.2       3  \n",
       "4   38.4       2  \n",
       "5   61.8       4  \n",
       "6   57.9       3  \n",
       "7   35.8       2  \n",
       "8   36.6       2  \n",
       "9   44.8       5  \n",
       "10  49.5       4  \n",
       "11  49.7       3  \n",
       "12  41.1       1  \n",
       "13  42.9       1  \n",
       "14  25.9       1  \n",
       "15  41.5       6  \n",
       "16  34.9       3  \n",
       "17  42.4       4  \n",
       "18  27.3       1  \n",
       "19  47.7       4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfP.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: The manager's goal is to have an average delivery time across all branches of less than 30 minutes.  Perform an appropriate hypothesis test at the $\\alpha=0.05$ significance level to evaluate whether this goal has been achieved.  Be sure to clearly state your null and alternate hypothesis, describe your testing procedure, and show all calculations in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "thanks stevey\n",
    "\n",
    "$H_0: \\mu = 30$\n",
    "\n",
    "$H_1: \\mu < 30$\n",
    "\n",
    "the testing process is a z-test where we compare the actual mean to the assummed mean(the actual mean delivert time to the restriction of 30 minutes) and divide by the quantity standard deveation over the square root of the sample size (1266).\n",
    "\n",
    "$$\\frac{\\bar{x} - \\mu}{\\frac{std}{\\sqrt{n}}}$$\n",
    "\n",
    "Then we compare this calculated value to out $z_{\\alpha}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We cannot reject the Null Hypothesis\n",
      "Z test result: -3.17120774749\n",
      "Z_alpha score: -1.64485362695\n"
     ]
    }
   ],
   "source": [
    "x_barTime = 30\n",
    "sigmaTime = dfP['time'].std()\n",
    "n=len(dfP)\n",
    "meanTime = dfP['time'].mean()\n",
    "z_score = stats.norm.ppf(.05)\n",
    "\n",
    "calcTime = (meanTime-x_barTime)/(sigmaTime/np.sqrt(n))\n",
    "\n",
    "if z_score > calc:\n",
    "    print(\"We cannot reject the Null Hypothesis\")\n",
    "else:\n",
    "    print(\"We reject the Null Hypothesis\")\n",
    "print(\"Z test result:\", calcTime)\n",
    "print(\"Z_alpha score:\", z_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: The manager also has the goal of having an average delivery temperature across all branches of greater than 65F.  Perform an appropriate hypothesis test at the $\\alpha=0.05$ significance level to evaluate whether this goal has been achieved.  Be sure to clearly state your null and alternate hypothesis, describe your testing procedure, and show all calculations in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the same test as part A. The only thing that changes here are the standard deveation and mean and true mean. Everything else should be the same. Oh and the side of the test, this is a right tail test as opposed to the left tail test because this is a comparision greater than a given value (65 degrees)\n",
    "\n",
    "$H_0: \\mu = 65$\n",
    "\n",
    "$H_1: \\mu > 65$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We cannot reject the Null Hypothesis\n",
      "Z test result: 1.3820886485\n",
      "Z_alpha score: 1.64485362695\n"
     ]
    }
   ],
   "source": [
    "x_barTemp = 65\n",
    "sigmaTemp = dfP['temperature'].std()\n",
    "meanTemp = dfP['temperature'].mean()\n",
    "\n",
    "calcTemp = (meanTemp-x_barTemp)/(sigmaTemp/np.sqrt(n))\n",
    "\n",
    "z_score = stats.norm.ppf(.95)\n",
    "\n",
    "if z_score > calc:\n",
    "    print(\"We cannot reject the Null Hypothesis\")\n",
    "else:\n",
    "    print(\"We reject the Null Hypothesis\")\n",
    "print(\"Z test result:\", calcTemp)\n",
    "print(\"Z_alpha score:\", z_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: The manager has enough money to give one of his delivery drivers a raise based on good performance. He knows from the data that his two best drivers are Mario and Luigi, but he's not sure if there is evidence that either one is better than the other.  Using delivery time and temperature as the criteria, perform any necessary hypothesis tests at the $\\alpha = 0.05$ significance level, to determine if one of the drivers deserves a raise. Be sure to clearly describe your hypotheses and methodology, and show any relevant computations in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0: \\mu_M - \\mu_L = 0$\n",
    "\n",
    "$H_1: \\mu_M - \\mu_L > 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-value for time: 0.00436618486748\n",
      "Z-value for temperature: -0.956537156319\n",
      "Range: -1.95996398454 to 1.95996398454\n"
     ]
    }
   ],
   "source": [
    "marioMeanTemp = dfP.loc[dfP['driver'] == \"Mario\", 'temperature'].mean()\n",
    "marioSigmaTemp = dfP.loc[dfP['driver'] == \"Mario\", 'temperature'].std()\n",
    "marioMeanTime = dfP.loc[dfP['driver'] == \"Mario\", 'time'].mean()\n",
    "marioSigmaTime = dfP.loc[dfP['driver'] == \"Mario\", 'time'].std()\n",
    "marioN = len(dfP.loc[dfP['driver'] == \"Mario\", 'temperature'])\n",
    "\n",
    "luigiMeanTemp = dfP.loc[dfP['driver'] == \"Luigi\", 'temperature'].mean()\n",
    "luigiSigmaTemp = dfP.loc[dfP['driver'] == \"Luigi\", 'temperature'].std()\n",
    "luigiMeanTime = dfP.loc[dfP['driver'] == \"Luigi\", 'time'].mean()\n",
    "luigiSigmaTime = dfP.loc[dfP['driver'] == \"Luigi\", 'time'].std()\n",
    "luigiN = len(dfP.loc[dfP['driver'] == \"Luigi\", 'temperature'])\n",
    "\n",
    "timeCalc = (marioMeanTime-luigiMeanTime)/np.sqrt(marioSigmaTime**2/(marioN)+luigiSigmaTime**2/(luigiN))\n",
    "tempCalc = (marioMeanTemp-luigiMeanTemp)/np.sqrt(marioSigmaTemp**2/(marioN)+luigiSigmaTemp**2/(luigiN))  \n",
    "\n",
    "print(\"Z-value for time:\", timeCalc)\n",
    "print(\"Z-value for temperature:\", tempCalc)\n",
    "print(\"Range:\", stats.norm.ppf(.025), \"to\", stats.norm.ppf(.975))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the z-values for both time and temperature are within the range of the 5% confidence interval, we can see that neither are significantly better. Therefore neither of them get the raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: On the other hand, the manager suspects that Salvatore has been underperforming as a driver.  The manager has a policy that if a pizza takes 40 minutes or longer to be delivered, he has to fork over a free bottle of wine.  This policy is only financially viable for the pizza chain if they have give out free wine on less than 5% of all pizza deliveries.  Perform a hypothesis test at the $\\alpha = 0.05$ significance level to determine if there is significant evidence that the proportion of Salvatore's deliveries that take longer than 40 minutes is greater than 5%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0: p = .05$<br\\>\n",
    "$H_1: p > .05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "salv = dfP.loc[dfP['driver'] == 'Salvatore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$z = \\frac{\\hat p - p}{\\sigma}$$\n",
    "\n",
    "$$\\sigma^2 = \\frac{p(1-p)}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z score: 0.445293626396\n",
      "Z alpha: 1.64485362695\n"
     ]
    }
   ],
   "source": [
    "x_bar = 40\n",
    "\n",
    "salvProp = len(salv.loc[salv['time']>40])/len(salv)\n",
    "sigma = np.sqrt(.05*(1-.05)/(len(salv)))\n",
    "\n",
    "z_score = (salvProp - .05)/sigma\n",
    "print(\"Z score:\",z_score)\n",
    "print(\"Z alpha:\", stats.norm.ppf(.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can see that the z_score is below the z alpha for the .05 significance level, we can determine that we cannot reject the null hypothesis and so we cannot say that Salvador's deliveries take longer than 40 minutes greater tha 5% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [15 points] Problem 4 - Naps vs Coffee for Memory? \n",
    "***\n",
    "\n",
    "The consumption of coffee to benefit alertness is a common activity practiced by 90% of adults in North America. Often coffee is used to replace the need for sleep. One recent study compares students’ ability to recall memorized information after either the consumption of coffee or a brief nap. A random sample of 24 adults\n",
    "were randomly divided into two groups and verbally given a list\n",
    "of 25 words to memorize. During a break, one of the groups took a nap for an hour and a half,\n",
    "another group stayed awake and were given a coffee an hour prior to testing. Researchers measured the number of words participants were\n",
    "able to recall following the break. The summary statistics for the two groups are shown below.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|c|c|c}\n",
    "\\textrm{Group} & \\textrm{Sample Size} & \\textrm{Mean} & \\textrm{Standard Deviation} \\\\\n",
    "\\hline \n",
    "\\textrm{Nap} & 12 & 15.5 & 3.2 \\\\ \n",
    "\\textrm{Coffee} & 12 & 12.25 & 3.1 \\\\ \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "In previous experiments the mean recall measurement was found to be normally distributed. \n",
    "\n",
    "**Part A**: Compute a 95% t-confidence interval for the mean recall measurement for participants that took a nap before the test. Do all computations in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-confidence interval: (13.299014839917051, 17.700985160082951)\n"
     ]
    }
   ],
   "source": [
    "nap_x_bar = 15.5\n",
    "nap_std = 3.2\n",
    "\n",
    "mu = 25\n",
    "n = 12\n",
    "\n",
    "t_val = stats.t.ppf(.975, 11)\n",
    "t_val\n",
    "interval = nap_x_bar - t_val, nap_x_bar + t_val\n",
    "\n",
    "print(\"T-confidence interval:\", interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Is there sufficient evidence, at the $\\alpha = 0.05$ significance level, to conclude that taking a nap promotes better memory recall that drinking coffee?  Be sure to clearly explain the test that you're doing and state all hypotheses. Do all computations in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z score: 2.52693300826\n",
      "Range: -1.95996398454 to 1.95996398454\n"
     ]
    }
   ],
   "source": [
    "coffee_x_bar = 12.25\n",
    "coffee_std = 3.1\n",
    "\n",
    "z_score = (nap_x_bar - coffee_x_bar)/np.sqrt((nap_std**2/n)+coffee_std**2/n)\n",
    "print(\"Z score:\",z_score)\n",
    "print(\"Range:\", stats.norm.ppf(.025), \"to\", stats.norm.ppf(.975))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the z score, we can see that there is a significant difference between naps and coffee because the 2.547>1.96 so we can concluse that there is a significant difference in favor of naps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Compute a 95% confidence interval for the standard deviation of memory recall for coffee drinkers. Do all computations in Python.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Chi-Squared Distribution, we will find the 95% confidence interval for the standard devation with the formula\n",
    "\n",
    "$$\\frac{(n-1)s^2}{X^2_{\\alpha/2, n-1}}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\frac{(n-1)s^2}{X^2_{1-\\alpha/2, n-1}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval: 2.19602496767 to 5.26342185494\n"
     ]
    }
   ],
   "source": [
    "left = np.sqrt((11*coffee_std**2)/stats.chi2.ppf(1-.05/2, 11))\n",
    "right = np.sqrt((11*coffee_std**2)/stats.chi2.ppf(.05/2, 11))\n",
    "\n",
    "print(\"Confidence interval:\",left,\"to\",right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [20 points] Problem 5 - Bad Science for Fun and Profit \n",
    "***\n",
    "\n",
    "[Data Dredging](https://en.wikipedia.org/wiki/Data_dredging) and [p-hacking](https://www.explainxkcd.com/wiki/index.php/882:_Significant) are umbrella terms for the dangerous practice of automatically testing a large number of hypotheses on the entirety or subsets of a single dataset in order to find statistically significant results. In this exercise we will focus on the idea of testing hypotheses on subsets of a single data set.  \n",
    "\n",
    "Johnny Nefarious has landed his first data science internship at an online marketing firm.  His primary summer project has been to design and test a new email advertisement for his company's best-selling product. To test his advertisement his supervisors have allowed him to send his ad to 4 targeted customer groups of 50 people every day for a month. \n",
    "\n",
    "The effectiveness of online advertising is typically measured by the ad's [click-through rate](https://en.wikipedia.org/wiki/Click-through_rate) (CTR), which is defined to be the _proportion_ of users that click on an advertisement. The company's standard email advertisement has a CTR of $0.05$.  Johnny is hoping to land a permanent position at the company when he graduates, so he's **really** motivated to show his supervisors that the CTR of his email advertisement is a (statistically) significant improvement over their previous ad. \n",
    "\n",
    "The data from Johnny's summer experiment can be found in email.csv. Load this dataset into Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oct  2 2017</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Oct  3 2017</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Oct  5 2017</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group         Date  Sent  Clicked\n",
       "0      1          NaN    50        1\n",
       "1      1  Oct  2 2017    50        2\n",
       "2      1  Oct  3 2017    50        4\n",
       "3      1          NaN    50        5\n",
       "4      1  Oct  5 2017    50        1"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAd = pd.read_csv(\"data/email.csv\")\n",
    "dfAd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: State the null and alternate hypotheses that Johnny should test to see if his ad campaign is an improvement over the company's standard mailer with a CTR of $0.05$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0: CTR = 0.05$\n",
    "\n",
    "$H_1: CTR > 0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Test the hypothesis from **Part A** at the $\\alpha = 0.05$ significance level using a p-value test. Is there sufficient evidence for Johnny to conclude that his ad campaign is an improvement?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value: 0.224365747475\n"
     ]
    }
   ],
   "source": [
    "length = len(dfAd)\n",
    "summ = dfAd[\"Clicked\"].sum()\n",
    "mean = summ/(50*length)\n",
    "z_score = (mean - 0.05)/np.sqrt(.05*(1-.05)/np.sum(dfAd[\"Sent\"]))\n",
    "\n",
    "p_val = 1-stats.norm.cdf(z_score)\n",
    "print(\"P Value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Bummer, Johnny thinks. This is the part where he decides to resort to some questionable science.  Maybe there is a reasonable subset of the data for which his alternative hypothesis is supported?  Can he find it?  Can he come up for a reasonable justification for why this subset of the data should be considered while the rest should be discarded? \n",
    "\n",
    "Here are the **rules**: Johnny cannot modify the original data (e.g. by adding nonexistent clicks to certain groups or days) because his boss will surely notice.  Instead he needs to find a subset of the data for which his hypothesis is supported by a p-value test at the $\\alpha = 0.05$ significance level _and_ be able to explain to his supervisors why his sub-selection of the data is reasonable.  \n",
    "\n",
    "In addition to your explanation of why your successful subset of the data is potentially reasonable, be sure to thoroughly explain the details of the tests that you perform and show all of your Python computation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value: 0.0336489140453\n"
     ]
    }
   ],
   "source": [
    "makeAdsGreatAgain = dfAd.loc[dfAd[\"Clicked\"] > 0]\n",
    "\n",
    "length = len(makeAdsGreatAgain)\n",
    "summ = makeAdsGreatAgain[\"Clicked\"].sum()\n",
    "mean = summ/(50*length)\n",
    "z_score = (mean - 0.05)/np.sqrt(.05*(1-.05)/np.sum(makeAdsGreatAgain[\"Sent\"]))\n",
    "\n",
    "p_val = 1-stats.norm.cdf(z_score)\n",
    "print(\"P Value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why the initail dataset was inaccurate to show how well the ad functions works is because people who dont licks ads are using ad blockers (i mean dont we all in this day and age). so by ignorring all the people that ignore me, we can see that my formula is actually doing a great job because my p-value is less than than of the alpha value (.0336 < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [20 points] Problem 6 - Simple Linear Regression for Gas Mileage \n",
    "***\n",
    "\n",
    "The data in auto.csv contains information on cars from the 1970s and 1980s. In this exercise you will construct a simple linear regression model for the response variable mpg with horsepower as the feature. Load the data into a Pandas DataFrame.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SORRY\n",
    "\n",
    "I just had a lot to do this week and was unable to make it to this last question. I honestly will look at this later for the sake of learning more about linear regression because this has actually popped up a lot in a few other classes this semester.\n",
    "\n",
    "**0 POINTS TO SREDO-CLAW**\n",
    "\n",
    "**30 POINTS TO DATASCI-FFENDOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>70</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>70</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>70</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ford torino</td>\n",
       "      <td>70</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  year   mpg  cylinders  horsepower  weight\n",
       "0  chevrolet chevelle malibu    70  18.0          8       130.0  3504.0\n",
       "1          buick skylark 320    70  15.0          8       165.0  3693.0\n",
       "2         plymouth satellite    70  18.0          8       150.0  3436.0\n",
       "3              amc rebel sst    70  16.0          8       150.0  3433.0\n",
       "4                ford torino    70  17.0          8       140.0  3449.0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAuto = pd.read_csv(\"data/auto.csv\")\n",
    "dfAuto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Perform a simple linear regression with horsepower as the feature and mpg as the response.  Report the estimated regression model in the form $Y = \\alpha + \\beta x$. Do all computations in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Make a scatter-plot of the data with horsepower as the feature and mpg as the response and overlay the estimated regression line. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Is the relationship between horsepower and mpg positive or negative? Justify your response. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Find a 95% confidence interval for the slope parameter.  Based on this confidence interval, is there sufficient evidence to believe, at the 95% confidence level, that there is a real relationship between horsepower and mpg? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Double-check your result from **Part D** by performing an equivalent hypothesis test.  Be sure to state your null and alternative hypotheses and explain your general methodology.  Do your conclusions agree with those made in **Part D**? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: What gas mileage would your simple linear regression model predict for a car with a horsepower of $97$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
